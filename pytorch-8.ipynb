{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-18T09:45:10.591445Z","iopub.execute_input":"2024-02-18T09:45:10.592569Z","iopub.status.idle":"2024-02-18T09:45:10.600715Z","shell.execute_reply.started":"2024-02-18T09:45:10.592509Z","shell.execute_reply":"2024-02-18T09:45:10.599278Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torchvision\n\nfrom torch import nn\nfrom torchvision import transforms, datasets\n\ntry:\n    from torchinfo import summary\nexcept:\n    !pip install -q torchinfo\n    from torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:10.602935Z","iopub.execute_input":"2024-02-18T09:45:10.603422Z","iopub.status.idle":"2024-02-18T09:45:10.613766Z","shell.execute_reply.started":"2024-02-18T09:45:10.603390Z","shell.execute_reply":"2024-02-18T09:45:10.612571Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:10.615434Z","iopub.execute_input":"2024-02-18T09:45:10.615785Z","iopub.status.idle":"2024-02-18T09:45:10.630156Z","shell.execute_reply.started":"2024-02-18T09:45:10.615755Z","shell.execute_reply":"2024-02-18T09:45:10.628915Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"import requests\nimport zipfile\n\nfrom pathlib import Path\n\ndata_path=Path(\"data/\")\nimage_path=data_path / \"pizza_steak_sushi\"\n\nimage_path.mkdir(parents=True, exist_ok=True)\n    \nwith open(data_path / \"pizza_steak_sushi.zip\",\"wb\") as f:\n    request=requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n    f.write(request.content)\n        \nwith zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\",\"r\")as zip_ref:\n    zip_ref.extractall(image_path)\n    \nos.remove(data_path / \"pizza_steak_sushi.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:10.633281Z","iopub.execute_input":"2024-02-18T09:45:10.633685Z","iopub.status.idle":"2024-02-18T09:45:11.148936Z","shell.execute_reply.started":"2024-02-18T09:45:10.633654Z","shell.execute_reply":"2024-02-18T09:45:11.147637Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_dir=image_path / \"train\"\ntest_dir=image_path / \"test\"\n\ntrain_dir, test_dir","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.150482Z","iopub.execute_input":"2024-02-18T09:45:11.150907Z","iopub.status.idle":"2024-02-18T09:45:11.159000Z","shell.execute_reply.started":"2024-02-18T09:45:11.150875Z","shell.execute_reply":"2024-02-18T09:45:11.157729Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(PosixPath('data/pizza_steak_sushi/train'),\n PosixPath('data/pizza_steak_sushi/test'))"},"metadata":{}}]},{"cell_type":"code","source":"data_transform=transforms.Compose([\n    \n    #resize the images to 64x64\n    transforms.Resize(size=(64,64)),\n    \n    # flip the images randomly on the horizontal\n    transforms.RandomHorizontalFlip(p=0.5), # p= probability of flip\n    \n    # turn the image into a torch.Tensor\n    transforms.ToTensor(), # this aslo convert all pixel value from 0to 255 to be between 0 and 1\n    \n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.161010Z","iopub.execute_input":"2024-02-18T09:45:11.161429Z","iopub.status.idle":"2024-02-18T09:45:11.172403Z","shell.execute_reply.started":"2024-02-18T09:45:11.161398Z","shell.execute_reply":"2024-02-18T09:45:11.171450Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# use ImageFolder to create datasets\ntrain_data=datasets.ImageFolder(root=train_dir, # target folderof image\n                                transform=data_transform, # \n                                target_transform=None)# transforms to perform on label (if necesary)\ntest_data=datasets.ImageFolder(root=test_dir,\n                               transform=data_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.174482Z","iopub.execute_input":"2024-02-18T09:45:11.174847Z","iopub.status.idle":"2024-02-18T09:45:11.188442Z","shell.execute_reply.started":"2024-02-18T09:45:11.174820Z","shell.execute_reply":"2024-02-18T09:45:11.187131Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# tur n train adn ttest datasets inot dataloaders\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader=DataLoader(dataset=train_data,\n                            batch_size=1,\n                            num_workers=1, # how many suprocess to usefor data loading?\n                            shuffle=True)\ntest_dataloader=DataLoader(dataset=test_data,\n                           batch_size=1,\n                           num_workers=1,\n                           shuffle=False)\ntrain_dataloader,test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.190094Z","iopub.execute_input":"2024-02-18T09:45:11.190534Z","iopub.status.idle":"2024-02-18T09:45:11.203471Z","shell.execute_reply.started":"2024-02-18T09:45:11.190496Z","shell.execute_reply":"2024-02-18T09:45:11.202181Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(<torch.utils.data.dataloader.DataLoader at 0x794e7c4b6500>,\n <torch.utils.data.dataloader.DataLoader at 0x794e7c4b6230>)"},"metadata":{}}]},{"cell_type":"code","source":"weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\nweights","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.205367Z","iopub.execute_input":"2024-02-18T09:45:11.206080Z","iopub.status.idle":"2024-02-18T09:45:11.217383Z","shell.execute_reply.started":"2024-02-18T09:45:11.206027Z","shell.execute_reply":"2024-02-18T09:45:11.216427Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"EfficientNet_B0_Weights.IMAGENET1K_V1"},"metadata":{}}]},{"cell_type":"code","source":"auto_transforms=weights.transforms()\nauto_transforms","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.222828Z","iopub.execute_input":"2024-02-18T09:45:11.223527Z","iopub.status.idle":"2024-02-18T09:45:11.234725Z","shell.execute_reply.started":"2024-02-18T09:45:11.223488Z","shell.execute_reply":"2024-02-18T09:45:11.233378Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BICUBIC\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_data=datasets.ImageFolder(root=train_dir, # target folderof image\n                                transform=data_transform, # \n                                target_transform=None)# transforms to perform on label (if necesary)\ntest_data=datasets.ImageFolder(root=test_dir,\n                               transform=data_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.236398Z","iopub.execute_input":"2024-02-18T09:45:11.236841Z","iopub.status.idle":"2024-02-18T09:45:11.246893Z","shell.execute_reply.started":"2024-02-18T09:45:11.236808Z","shell.execute_reply":"2024-02-18T09:45:11.245848Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_dataloader=DataLoader(dataset=train_data,\n                            batch_size=1,\n                            num_workers=1, # how many suprocess to usefor data loading?\n                            shuffle=True)\ntest_dataloader=DataLoader(dataset=test_data,\n                           batch_size=1,\n                           num_workers=1,\n                           shuffle=False)\ntrain_dataloader,test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.248105Z","iopub.execute_input":"2024-02-18T09:45:11.249136Z","iopub.status.idle":"2024-02-18T09:45:11.259262Z","shell.execute_reply.started":"2024-02-18T09:45:11.249090Z","shell.execute_reply":"2024-02-18T09:45:11.258261Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"(<torch.utils.data.dataloader.DataLoader at 0x794e7c433dc0>,\n <torch.utils.data.dataloader.DataLoader at 0x794e7c432fb0>)"},"metadata":{}}]},{"cell_type":"code","source":"weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\nmodel=torchvision.models.efficientnet_b0(weights).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.260825Z","iopub.execute_input":"2024-02-18T09:45:11.261522Z","iopub.status.idle":"2024-02-18T09:45:11.504491Z","shell.execute_reply.started":"2024-02-18T09:45:11.261477Z","shell.execute_reply":"2024-02-18T09:45:11.503096Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=True)\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"summary(model=model,\n        input_size=(32, 3, 224, 224),\n        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:11.506112Z","iopub.execute_input":"2024-02-18T09:45:11.506772Z","iopub.status.idle":"2024-02-18T09:45:13.514787Z","shell.execute_reply.started":"2024-02-18T09:45:11.506738Z","shell.execute_reply":"2024-02-18T09:45:13.513326Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"============================================================================================================================================\nLayer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n============================================================================================================================================\nEfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n├─Sequential (classifier)                                    [32, 1280]           [32, 1000]           --                   True\n│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n│    └─Linear (1)                                            [32, 1280]           [32, 1000]           1,281,000            True\n============================================================================================================================================\nTotal params: 5,288,548\nTrainable params: 5,288,548\nNon-trainable params: 0\nTotal mult-adds (G): 12.35\n============================================================================================================================================\nInput size (MB): 19.27\nForward/backward pass size (MB): 3452.35\nParams size (MB): 21.15\nEstimated Total Size (MB): 3492.77\n============================================================================================================================================"},"metadata":{}}]},{"cell_type":"code","source":"# freeze all base layers in the \"features\" section of the model\nfor param in model.features.parameters():\n    param.requires_grad=False ","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:13.516446Z","iopub.execute_input":"2024-02-18T09:45:13.516888Z","iopub.status.idle":"2024-02-18T09:45:13.525082Z","shell.execute_reply.started":"2024-02-18T09:45:13.516855Z","shell.execute_reply":"2024-02-18T09:45:13.523423Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(29)\n\ntorch.cuda.manual_seed(29)\n\noutput_shape=3\n\nmodel.classifier=torch.nn.Sequential(\n    torch.nn.Dropout(p=0.2,inplace=True),\n    torch.nn.Linear(in_features=1280,\n                    out_features=output_shape,\n                    bias=True)\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:13.526873Z","iopub.execute_input":"2024-02-18T09:45:13.527300Z","iopub.status.idle":"2024-02-18T09:45:13.541866Z","shell.execute_reply.started":"2024-02-18T09:45:13.527269Z","shell.execute_reply":"2024-02-18T09:45:13.540327Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"summary(model=model,\n        input_size=(32, 3, 224, 224),\n        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:13.544065Z","iopub.execute_input":"2024-02-18T09:45:13.544539Z","iopub.status.idle":"2024-02-18T09:45:16.082857Z","shell.execute_reply.started":"2024-02-18T09:45:13.544486Z","shell.execute_reply":"2024-02-18T09:45:16.081353Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"============================================================================================================================================\nLayer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n============================================================================================================================================\nEfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n============================================================================================================================================\nTotal params: 4,011,391\nTrainable params: 3,843\nNon-trainable params: 4,007,548\nTotal mult-adds (G): 12.31\n============================================================================================================================================\nInput size (MB): 19.27\nForward/backward pass size (MB): 3452.09\nParams size (MB): 16.05\nEstimated Total Size (MB): 3487.41\n============================================================================================================================================"},"metadata":{}}]},{"cell_type":"code","source":"loss_fn=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),\n                          lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:16.084914Z","iopub.execute_input":"2024-02-18T09:45:16.085320Z","iopub.status.idle":"2024-02-18T09:45:16.093900Z","shell.execute_reply.started":"2024-02-18T09:45:16.085288Z","shell.execute_reply":"2024-02-18T09:45:16.092897Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def train_step(model:torch.nn.Module,\n               dataloader:torch.utils.data.DataLoader,\n               loss_fn:torch.nn.Module,\n               optimizer:torch.optim.Optimizer):\n    model.train()\n    \n    train_loss, train_acc=0,0\n    \n    for batch, (X,y) in enumerate(dataloader):\n        X,y=X.to(device), y.to(device)\n        \n        y_pred=model(X)\n        \n        loss=loss_fn(y_pred,y)\n        train_loss+=loss.item()\n        \n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n        train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n    \n    # adjust metrics to get average loss and accuracy pre batch\n    train_loss=train_loss / len(dataloader)\n    train_acc=train_acc/ len(dataloader)\n    \n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:16.095573Z","iopub.execute_input":"2024-02-18T09:45:16.096038Z","iopub.status.idle":"2024-02-18T09:45:16.107729Z","shell.execute_reply.started":"2024-02-18T09:45:16.096001Z","shell.execute_reply":"2024-02-18T09:45:16.106197Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def test_step(model:torch.nn.Module,\n              dataloader:torch.utils.data.DataLoader,\n              loss_fn:torch.nn.Module):\n    \n    model.eval()\n    \n    test_loss, test_acc=0,0\n    \n    with torch.inference_mode():\n        for batch, (X,y) in enumerate(dataloader):\n            X,y=X.to(device), y.to(device)\n            \n            test_pred_logits=model(X)\n            \n            loss=loss_fn(test_pred_logits,y)\n            test_loss+=loss.item()\n            \n            test_pred_labels=test_pred_logits.argmax(dim=1)\n            test_acc+=((test_pred_labels==y).sum().item() / len(test_pred_labels))\n            \n    test_loss/=len(dataloader)\n    test_acc/=len(dataloader)\n    return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:16.109492Z","iopub.execute_input":"2024-02-18T09:45:16.109929Z","iopub.status.idle":"2024-02-18T09:45:16.123726Z","shell.execute_reply.started":"2024-02-18T09:45:16.109894Z","shell.execute_reply":"2024-02-18T09:45:16.122486Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\n\ndef train(model:torch.nn.Module,\n          train_dataloader:torch.utils.data.DataLoader,\n          test_dataloader:torch.utils.data.DataLoader,\n          optimizer:torch.optim.Optimizer,\n          loss_fn:torch.nn.Module,\n          epochs:int=5):\n    results={\"train_loss\":[],\n             \"train_acc\":[],\n             \"test_loss\":[],\n             \"test_acc\":[]}\n    \n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc=train_step(model=model,\n                                         dataloader=train_dataloader,\n                                         loss_fn=loss_fn,\n                                         optimizer=optimizer)\n        test_loss, test_acc=test_step(model=model,\n                                      dataloader=test_dataloader,\n                                      loss_fn=loss_fn)\n        \n        print(\n            f\"{epoch+1} | \" \n            f\"train_loss: {train_loss} | \"\n            f\"train_acc: {train_acc} | \"            \n            f\"test_loss: {test_loss} | \"\n            f\"test_acc: {test_acc} \"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n        # Experimint tracking\n        writer=SummaryWriter()\n        \n        # add loss results to summary writer\n        writer.add_scalars(main_tag=\"Loss\",\n                           tag_scalar_dict={\"train_loss\":train_loss,\n                                           \"test_loss\":test_loss},\n                           global_step=epochs\n                        )\n        # add accuracy results to SummaryWriter\n        writer.add_scalars(main_tag=\"Accuracy\",\n                           tag_scalar_dict={\"train_acc\":train_acc,\n                                            \"test_acc\":test_acc},\n                           global_step=epochs\n                        )\n        \n        # track the pytorch model architeccture\n        writer.add_graph(model=model,\n                         input_to_model=torch.randn(32,3,224,224).to(device))\n    writer.close()\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:16.126347Z","iopub.execute_input":"2024-02-18T09:45:16.126749Z","iopub.status.idle":"2024-02-18T09:45:16.144876Z","shell.execute_reply.started":"2024-02-18T09:45:16.126700Z","shell.execute_reply":"2024-02-18T09:45:16.143373Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(29)\ntorch.cuda.manual_seed(29)\n\nresults=train(model=model,\n              train_dataloader=train_dataloader,\n              test_dataloader=test_dataloader,\n              optimizer=optimizer,\n              loss_fn=loss_fn,\n              epochs=5,\n              )","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:45:16.148586Z","iopub.execute_input":"2024-02-18T09:45:16.149090Z","iopub.status.idle":"2024-02-18T09:47:03.662992Z","shell.execute_reply.started":"2024-02-18T09:45:16.149032Z","shell.execute_reply":"2024-02-18T09:47:03.661175Z"},"trusted":true},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a130150d7349be914f684fee7a869f"}},"metadata":{}},{"name":"stdout","text":"1 | train_loss: 1.7380478501588934 | train_acc: 0.3422222222222222 | test_loss: 24.731089765882963 | test_acc: 0.30666666666666664 \n2 | train_loss: 2.2342430224041974 | train_acc: 0.29333333333333333 | test_loss: 14.397330179707447 | test_acc: 0.3333333333333333 \n3 | train_loss: 1.8697436951571662 | train_acc: 0.38666666666666666 | test_loss: 18.58480136554159 | test_acc: 0.3333333333333333 \n4 | train_loss: 1.821028441426396 | train_acc: 0.4444444444444444 | test_loss: 17.84432128576974 | test_acc: 0.3333333333333333 \n5 | train_loss: 1.9106864041299558 | train_acc: 0.4577777777777778 | test_loss: 20.188492110509777 | test_acc: 0.29333333333333333 \n","output_type":"stream"}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.665106Z","iopub.execute_input":"2024-02-18T09:47:03.665618Z","iopub.status.idle":"2024-02-18T09:47:03.677241Z","shell.execute_reply.started":"2024-02-18T09:47:03.665524Z","shell.execute_reply":"2024-02-18T09:47:03.675853Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"{'train_loss': [1.7380478501588934,\n  2.2342430224041974,\n  1.8697436951571662,\n  1.821028441426396,\n  1.9106864041299558],\n 'train_acc': [0.3422222222222222,\n  0.29333333333333333,\n  0.38666666666666666,\n  0.4444444444444444,\n  0.4577777777777778],\n 'test_loss': [24.731089765882963,\n  14.397330179707447,\n  18.58480136554159,\n  17.84432128576974,\n  20.188492110509777],\n 'test_acc': [0.30666666666666664,\n  0.3333333333333333,\n  0.3333333333333333,\n  0.3333333333333333,\n  0.29333333333333333]}"},"metadata":{}}]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir runs","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.678917Z","iopub.execute_input":"2024-02-18T09:47:03.679346Z","iopub.status.idle":"2024-02-18T09:47:03.707418Z","shell.execute_reply.started":"2024-02-18T09:47:03.679313Z","shell.execute_reply":"2024-02-18T09:47:03.705966Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reusing TensorBoard on port 6006 (pid 1265), started 0:30:50 ago. (Use '!kill 1265' to kill it.)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-46cbe4538bc16baf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-46cbe4538bc16baf\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"def create_writer(experiment_name:str,\n                  model_name:str,\n                  extra:str=None)-> torch.utils.tensorboard.writer.SummaryWriter():\n    \n    from datetime import datetime\n    import os\n    \n    timestamp=datetime.now().strftime(\"Y-%m-%d\")\n    \n    if extra:\n        log_dir=os.path.join(\"runs\",timestamp, experiment_name, model_name, extra)\n    else:\n        log_dir=os.path.join(\"runs\",timestamp, experiment_name, model_name)\n        \n    return SummaryWriter(log_dir=log_dir)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.708845Z","iopub.execute_input":"2024-02-18T09:47:03.709867Z","iopub.status.idle":"2024-02-18T09:47:03.719828Z","shell.execute_reply.started":"2024-02-18T09:47:03.709827Z","shell.execute_reply":"2024-02-18T09:47:03.718639Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"example_writer=create_writer(experiment_name=\"data_10_percent\",\n                             model_name=\"efficienb0\",\n                             extra=\"5_epochs\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.721753Z","iopub.execute_input":"2024-02-18T09:47:03.722535Z","iopub.status.idle":"2024-02-18T09:47:03.736398Z","shell.execute_reply.started":"2024-02-18T09:47:03.722497Z","shell.execute_reply":"2024-02-18T09:47:03.734847Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from typing import Dict, List\nfrom torch.utils.tensorboard import SummaryWriter\n\ndef train(model:torch.nn.Module,\n          train_dataloader:torch.utils.data.DataLoader,\n          test_dataloader:torch.utils.data.DataLoader,\n          optimizer:torch.optim.Optimizer,\n          loss_fn:torch.nn.Module,\n          writer:torch.utils.tensorboard.writer.SummaryWriter,\n          epochs:int=5)-> Dict[str, List]:\n    results={\"train_loss\":[],\n             \"train_acc\":[],\n             \"test_loss\":[],\n             \"test_acc\":[]}\n    \n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc=train_step(model=model,\n                                         dataloader=train_dataloader,\n                                         loss_fn=loss_fn,\n                                         optimizer=optimizer)\n        test_loss, test_acc=test_step(model=model,\n                                      dataloader=test_dataloader,\n                                      loss_fn=loss_fn)\n        \n        print(\n            f\"{epoch+1} | \" \n            f\"train_loss: {train_loss} | \"\n            f\"train_acc: {train_acc} | \"            \n            f\"test_loss: {test_loss} | \"\n            f\"test_acc: {test_acc} \"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n        # Experimint tracking\n        \n        # see if ther is a writer, if so , log it\n        # add loss results to summary writer\n        if writer:\n            writer.add_scalars(main_tag=\"Loss\",\n                               tag_scalar_dict={\"train_loss\":train_loss,\n                                               \"test_loss\":test_loss},\n                               global_step=epochs\n                            )\n            # add accuracy results to SummaryWriter\n            writer.add_scalars(main_tag=\"Accuracy\",\n                               tag_scalar_dict={\"train_acc\":train_acc,\n                                                \"test_acc\":test_acc},\n                               global_step=epochs\n                            )\n        \n            writer.close()\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.739015Z","iopub.execute_input":"2024-02-18T09:47:03.740525Z","iopub.status.idle":"2024-02-18T09:47:03.756077Z","shell.execute_reply.started":"2024-02-18T09:47:03.740462Z","shell.execute_reply":"2024-02-18T09:47:03.754428Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"import os \nimport zipfile\n\nfrom pathlib import Path\n\ndef download_data(source:str,\n                  destination:str,\n                  remove_source:bool=True) -> Path:\n                  \n    data_path=Path(\"data/\")\n    image_path=data_path / destination\n                  \n    if image_path.is_dir()==False:\n\n        image_path.mkdir(parents=True, exist_ok=True)\n\n        with open(data_path / \"pizza_steak_sushi.zip\",\"wb\") as f:\n            request=requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n            f.write(request.content)\n\n        with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\",\"r\")as zip_ref:\n            zip_ref.extractall(image_path)\n        \n        if remove_source:\n            os.remove(data_path / \"pizza_steak_sushi.zip\")\n    return image_path","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.763589Z","iopub.execute_input":"2024-02-18T09:47:03.764103Z","iopub.status.idle":"2024-02-18T09:47:03.776515Z","shell.execute_reply.started":"2024-02-18T09:47:03.764031Z","shell.execute_reply":"2024-02-18T09:47:03.775152Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Download 10 percent and 20 percent training data (if necessary)\ndata_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n                                     destination=\"pizza_steak_sushi\")\n\ndata_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n                                     destination=\"pizza_steak_sushi_20_percent\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:47:03.778245Z","iopub.execute_input":"2024-02-18T09:47:03.778660Z","iopub.status.idle":"2024-02-18T09:47:03.793986Z","shell.execute_reply.started":"2024-02-18T09:47:03.778627Z","shell.execute_reply":"2024-02-18T09:47:03.792735Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"train_dir_10_percent=data_10_percent_path / \"train\"\ntrain_dir_20_percent=data_20_percent_path / \"train\"\ntest_dir=image_path / \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:49:10.303531Z","iopub.execute_input":"2024-02-18T09:49:10.303989Z","iopub.status.idle":"2024-02-18T09:49:10.310862Z","shell.execute_reply.started":"2024-02-18T09:49:10.303957Z","shell.execute_reply":"2024-02-18T09:49:10.309223Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"simple_transform=transforms.Compose([\n    \n    #resize the images to 64x64\n    transforms.Resize(size=(64,64)),\n    \n    # flip the images randomly on the horizontal\n    transforms.RandomHorizontalFlip(p=0.5), # p= probability of flip\n    \n    # turn the image into a torch.Tensor\n    transforms.ToTensor(), # this aslo convert all pixel value from 0to 255 to be between 0 and 1\n    \n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:49:11.884372Z","iopub.execute_input":"2024-02-18T09:49:11.885177Z","iopub.status.idle":"2024-02-18T09:49:11.892803Z","shell.execute_reply.started":"2024-02-18T09:49:11.885130Z","shell.execute_reply":"2024-02-18T09:49:11.891744Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets as datasets\n# use ImageFolder to create datasets\ntrain_data_10_percent=datasets.ImageFolder(root=train_dir_10_percent, # target folderof image\n                                transform=data_transform, # \n                                target_transform=None)# transforms to perform on label (if necesary)\ntrain_data_20_percent=datasets.ImageFolder(root=train_dir_20_percent, # target folderof image\n                                transform=data_transform, # \n                                target_transform=None)# transforms to perform on label (if necesary)\ntest_data=datasets.ImageFolder(root=test_dir,\n                               transform=data_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:58:57.104869Z","iopub.execute_input":"2024-02-18T09:58:57.105363Z","iopub.status.idle":"2024-02-18T09:58:57.118222Z","shell.execute_reply.started":"2024-02-18T09:58:57.105330Z","shell.execute_reply":"2024-02-18T09:58:57.116564Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"train_dataloader_10_percent=DataLoader(dataset=train_data_10_percent,\n                            batch_size=32,\n                            num_workers=1, # how many suprocess to usefor data loading?\n                            shuffle=True)\ntrain_dataloader_20_percent=DataLoader(dataset=train_data_20_percent,\n                            batch_size=32,\n                            num_workers=1, # how many suprocess to usefor data loading?\n                            shuffle=True)\n\ntest_dataloader=DataLoader(dataset=test_data,\n                           batch_size=32,\n                           num_workers=1,\n                           shuffle=False)\ntrain_dataloader_10_percent, train_dataloader_10_percent, test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:59:51.499881Z","iopub.execute_input":"2024-02-18T09:59:51.500751Z","iopub.status.idle":"2024-02-18T09:59:51.512245Z","shell.execute_reply.started":"2024-02-18T09:59:51.500703Z","shell.execute_reply":"2024-02-18T09:59:51.510848Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"(<torch.utils.data.dataloader.DataLoader at 0x794efd469570>,\n <torch.utils.data.dataloader.DataLoader at 0x794efd469570>,\n <torch.utils.data.dataloader.DataLoader at 0x794efd469540>)"},"metadata":{}}]},{"cell_type":"code","source":"import torchvision\nfrom torchinfo import summary\n\neffnetb2_weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\neffnetb2=torchvision.models.efficientnet_b2(weights=effnetb2_weights)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:03:43.954439Z","iopub.execute_input":"2024-02-18T10:03:43.954887Z","iopub.status.idle":"2024-02-18T10:03:44.857030Z","shell.execute_reply.started":"2024-02-18T10:03:43.954854Z","shell.execute_reply":"2024-02-18T10:03:44.855338Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n100%|██████████| 35.2M/35.2M [00:00<00:00, 113MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torch import nn\n\nOUT_FEATURES=3\n\ndef create_effnetb0():\n    \n    effnetb2_weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n    effnetb2=torchvision.models.efficientnet_b0(weights=effnetb2_weights)\n    \n    for param in model.features.parameters():\n        param.requires_grad=False\n        \n    torch.manual_seed(29)\n    torch.cuda.manual_seed(29)\n    \n    model.classifier=nn.Sequential(\n        nn.Dropout(p=0.2),\n        nn.Linear(in_features=1280, \n                  out_features=OUT_FEATURES)\n    ).to(device)\n    \n    model.name=\"effnetb0\"\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:13:15.754577Z","iopub.execute_input":"2024-02-18T10:13:15.755127Z","iopub.status.idle":"2024-02-18T10:13:15.766159Z","shell.execute_reply.started":"2024-02-18T10:13:15.755078Z","shell.execute_reply":"2024-02-18T10:13:15.763606Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"def create_effnetb2():\n    \n    effnetb2_weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\n    effnetb2=torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n    \n    for param in model.features.parameters():\n        param.requires_grad=False\n        \n    torch.manual_seed(29)\n    torch.cuda.manual_seed(29)\n    \n    model.classifier=nn.Sequential(\n        nn.Dropout(p=0.3),\n        nn.Linear(in_features=1408, \n                  out_features=OUT_FEATURES)\n    ).to(device)\n    \n    model.name=\"effnetb2\"\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:13:16.043463Z","iopub.execute_input":"2024-02-18T10:13:16.043908Z","iopub.status.idle":"2024-02-18T10:13:16.054325Z","shell.execute_reply.started":"2024-02-18T10:13:16.043876Z","shell.execute_reply":"2024-02-18T10:13:16.052413Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"effnetb0=create_effnetb0()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:13:28.489745Z","iopub.execute_input":"2024-02-18T10:13:28.490228Z","iopub.status.idle":"2024-02-18T10:13:28.693926Z","shell.execute_reply.started":"2024-02-18T10:13:28.490194Z","shell.execute_reply":"2024-02-18T10:13:28.692402Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"effnetb2=create_effnetb2()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:13:50.358495Z","iopub.execute_input":"2024-02-18T10:13:50.358938Z","iopub.status.idle":"2024-02-18T10:13:50.671575Z","shell.execute_reply.started":"2024-02-18T10:13:50.358908Z","shell.execute_reply":"2024-02-18T10:13:50.670144Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"summary(model=effnetb0,\n        input_size=(32, 3, 224, 224),\n        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:18:54.329235Z","iopub.execute_input":"2024-02-18T10:18:54.330695Z","iopub.status.idle":"2024-02-18T10:18:56.868731Z","shell.execute_reply.started":"2024-02-18T10:18:54.330629Z","shell.execute_reply":"2024-02-18T10:18:56.866388Z"},"trusted":true},"execution_count":110,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:338\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    336\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x1280 and 1408x3)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffnetb0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvar_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2dNormActivation: 2, Conv2d: 3, BatchNorm2d: 3, SiLU: 3, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, Conv2dNormActivation: 2, Conv2d: 3, BatchNorm2d: 3, SiLU: 3, AdaptiveAvgPool2d: 1, Dropout: 2]"],"ename":"RuntimeError","evalue":"Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2dNormActivation: 2, Conv2d: 3, BatchNorm2d: 3, SiLU: 3, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, StochasticDepth: 4, Sequential: 2, MBConv: 3, Sequential: 4, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, SiLU: 6, SqueezeExcitation: 5, AdaptiveAvgPool2d: 6, Conv2d: 6, SiLU: 6, Conv2d: 6, Sigmoid: 6, Conv2dNormActivation: 5, Conv2d: 6, BatchNorm2d: 6, Conv2dNormActivation: 2, Conv2d: 3, BatchNorm2d: 3, SiLU: 3, AdaptiveAvgPool2d: 1, Dropout: 2]","output_type":"error"}]},{"cell_type":"code","source":"num_epochs=[5,10]\n\nmodels=[\"effnetb0\",\"effnetb2\"]\n\ntrain_dataloaders={\"data_10_percent\":train_dataloader_10_percent,\n                   \"data_20_percent\":train_data_20_percent}","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:20:58.489543Z","iopub.execute_input":"2024-02-18T10:20:58.490103Z","iopub.status.idle":"2024-02-18T10:20:58.496455Z","shell.execute_reply.started":"2024-02-18T10:20:58.490039Z","shell.execute_reply":"2024-02-18T10:20:58.495245Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"%%time\n\nexperiment_number=0\n\nfor dataloader_name, train_dataloader in train_dataloaders.items():\n    for epochs in num_epochs:\n        for model_name in models:\n            experiment_number+=1\n        \n            print(experiment_number)\n            print(model_name)\n            print(dataloader_name)\n            print(epochs)\n            \n            if model_name==\"effnetb0\":\n                model=create_effnetb0()\n            else:\n                model=create_effnetb2()\n            \n            loss_fn=nn.CrossEntropyLoss()\n            optimizer=torch.optim.Adam(params=model.parameters(),lr=0.01)\n            \n            train(model=model,\n                  train_dataloader=train_dataloader,\n                  test_dataloader=test_dataloader,\n                  optimizer=optimizer,\n                  loss_fn=loss_fn,\n                  epochs=epochs,\n                  writer=create_writer(experiment_name=dataloader_name,\n                                       model_name=model_name,\n                                       extra=f\"epochs: {epochs}\"))        ","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:33:14.685659Z","iopub.execute_input":"2024-02-18T10:33:14.687035Z","iopub.status.idle":"2024-02-18T10:33:29.973463Z","shell.execute_reply.started":"2024-02-18T10:33:14.686986Z","shell.execute_reply":"2024-02-18T10:33:29.971511Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"1\neffnetb0\ndata_10_percent\n5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2c69d6f73b4ee18907651a62e37243"}},"metadata":{}},{"name":"stdout","text":"1 | train_loss: 1.1265328451991081 | train_acc: 0.421875 | test_loss: 1.0675922632217407 | test_acc: 0.49526515151515155 \n2 | train_loss: 0.8807534277439117 | train_acc: 0.5859375 | test_loss: 1.014660159746806 | test_acc: 0.537878787878788 \n3 | train_loss: 0.766521580517292 | train_acc: 0.63671875 | test_loss: 0.840299387772878 | test_acc: 0.6590909090909091 \n4 | train_loss: 0.8942751996219158 | train_acc: 0.66015625 | test_loss: 1.1021015445391338 | test_acc: 0.6410984848484849 \n5 | train_loss: 0.7340848110616207 | train_acc: 0.6796875 | test_loss: 0.8133730888366699 | test_acc: 0.7509469696969697 \n2\neffnetb2\ndata_10_percent\n5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4582d2eb989f4bf491676d056b91a960"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m<timed exec>:21\u001b[0m\n","Cell \u001b[0;32mIn[72], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, writer, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m results\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\n\u001b[1;32m     12\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\n\u001b[1;32m     13\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\n\u001b[1;32m     14\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 17\u001b[0m     train_loss, train_acc\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     test_loss, test_acc\u001b[38;5;241m=\u001b[39mtest_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     22\u001b[0m                                   dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     23\u001b[0m                                   loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n","Cell \u001b[0;32mIn[64], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     X,y\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss_fn(y_pred,y)\n\u001b[1;32m     15\u001b[0m     train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:338\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    335\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x1280 and 1408x3)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x1280 and 1408x3)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}