{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\ntorch.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nimport zipfile\n\nfrom pathlib import Path\n\ndata_path=Path(\"data/\")\nimage_path=data_path / \"pizza_steak_sushi\"\n\nimage_path.mkdir(parents=True, exist_ok=True)\n    \nwith open(data_path / \"pizza_steak_sushi.zip\",\"wb\") as f:\n    request=requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n    f.write(request.content)\n        \nwith zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\",\"r\")as zip_ref:\n    zip_ref.extractall(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef walk_through_dir(dir_path):\n#     pass\n    for dirpath, dirname, filenames in os.walk(dir_path):\n        print(len(dirname), len(filenames), dirpath)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walk_through_dir(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir=image_path / \"train\"\ntest_dir=image_path / \"test\"\n\ntrain_dir, test_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom PIL import Image\n\nrandom.seed(42)\n\n# get all image paths (* means \"any combination\")\nimage_path_list=list(image_path.glob(\"*/*/*.jpg\"))\n\n# get random image path\nrandom_img_path=random.choice(image_path_list)\n\n# get image class fro path name\nimage_class=random_img_path.parent.stem\n\n# open image\nimg=Image.open(random_img_path)\n\nprint(random_img_path)\nprint(image_class)\nprint(img.height)\nprint(img.width)\nimg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transform=transforms.Compose([\n    \n    #resize the images to 64x64\n    transforms.Resize(size=(64,64)),\n    \n    # flip the images randomly on the horizontal\n    transforms.RandomHorizontalFlip(p=0.5), # p= probability of flip\n    \n    # turn the image into a torch.Tensor\n    transforms.ToTensor() # this aslo convert all pixel value from 0to 255 to be between 0 and 1\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimg_as_array=np.asarray(img)\n\nplt.figure(figsize=(10,7))\nplt.imshow(img_as_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_transformed_images(image_paths, transform, n=3, seed=29):\n    random.seed(seed)\n    random_image_paths=random.sample(image_paths, k=n)\n    for image_path in random_image_paths:\n        with Image.open(image_path) as f:\n            fig, ax=plt.subplots(1,2)\n            ax[0].imshow(f)\n            ax[0].set_title(f.size)\n            ax[0].axis(\"off\")\n            \n            # trasnform and plot mage\n            # permute() will change shape of image to suit matplotlib\n            # pytorch default is [C,H,W] But matplotlib is [H,W,C]\n            transformed_image=transform(f).permute(1,2,0)\n            ax[1].imshow(transformed_image)\n            ax[1].set_title(transformed_image.shape)\n            ax[1].axis(False)\n            \n            fig.suptitle(image_path.parent.stem,fontsize=16)\n            \nplot_transformed_images(image_path_list,\n                        transform=data_transform,\n                        n=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use ImageFolder to create datasets\ntrain_data=datasets.ImageFolder(root=train_dir, # target folderof image\n                                transform=data_transform, # \n                                target_transform=None)# transforms to perform on label (if necesary)\ntest_data=datasets.ImageFolder(root=test_dir,\n                               transform=data_transform)\nprint(train_data,test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=train_data.classes\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict=train_data.class_to_idx\nclass_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label=train_data[0][0], train_data[0][1]\nprint(img, img.shape)\nprint(\"\\n\")\n\nprint(img.dtype)\nprint(\"\\n\")\nprint(label, type(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rearrange the order of dimensions\nimg_permute=img.permute(1,2,0)\n\n# print out different shapes (before and after permute)\nprint(f\"{img.shape} ->[color_channels,h,w]\")\nprint(f\"{img_permute.shape} -> [h,w,color_channels]\")\n\nplt.figure(figsize=(10,7))\nplt.imshow(img.permute(1,2,0))\n# plt.axis(False)\nplt.title(class_names[label])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tur n train adn ttest datasets inot dataloaders\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader=DataLoader(dataset=train_data,\n                            batch_size=1,\n                            num_workers=1, # how many suprocess to usefor data loading?\n                            shuffle=True)\ntest_dataloader=DataLoader(dataset=test_data,\n                           batch_size=1,\n                           num_workers=1,\n                           shuffle=False)\ntrain_dataloader,test_dataloader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label=next(iter(train_dataloader))\n\nprint(f\"{img.shape} -> [batch_size,cc,h,w]\")\nprint(label.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom typing import Tuple, Dict, List","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.classes, train_data.class_to_idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup path for target directiory\ntarget_directory=train_dir\nprint(target_directory)\n\nclass_names_found=sorted(entry.name for entry in list(os.scandir(image_path / \"train\")))\nprint(class_names_found)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_classes(directory)-> Tuple[List[str], Dict[str,int]]:\n    # get the classes by scanning the target directory\n    classes=sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n    \n    # raise an error if class names not found\n    if not classes:\n        raise FileNotFoundError(f\"couldn't find any classes in {directory}\")\n    \n    # create a directory of index labels (computer prefer numerical rather than string labels)\n    class_to_idx={cls_name:i for i, cls_name in enumerate(classes) }\n    return classes, class_to_idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"find_classes(train_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n# subclass torch.utils.data.Dataset\nclass ImageFolderCustom(Dataset):\n\n    # initialize with a targ_dir and transform parameter\n    def __init__(self,targ_dir:str, transform=None)->None:\n        # create class attributes \n        \n        # get all image paths\n        self.paths=list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n        \n        # setup transforms\n        self.transform=transform\n        \n        self.classes, self.classes_to_idx=find_classes(targ_dir)\n        \n    def load_image(self,index:int)->Image.Image:\n        image_path=self.paths[index]\n        return Image.open(image_path)\n    \n    # overwrite the __len__() method (optional but recommended fro subclasses of torch.utils.data.Dataset)\n    def __len__(self)->int:\n        return len(self.paths)\n    \n    # overwrite the __getiitem__() method (required fro subclasses of torch.utils.data.Dataset)\n    def __getitem__(self,index:int)->Tuple[torch.Tensor,int]:\n        img=self.load_image(index)\n        class_name=self.paths[index].parent.name\n        class_idx=self.classes_to_idx[class_name]\n        \n        if self.transform:\n            return self.transform(img), class_idx\n        else:\n            return img, clas_idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# augment train data\ntrain_transforms=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor()\n])\n\n# don't augmenyt test data only reshape\ntest_transforms=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_custom=ImageFolderCustom(targ_dir=train_dir,\n                                   transform=train_transforms)\ntest_data_custom=ImageFolderCustom(targ_dir=test_dir,\n                                   transform=test_transforms)\n\ntrain_data_custom,test_data_custom","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data_custom),len(test_data_custom)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_custom.classes,train_data_custom.classes_to_idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((len(train_data_custom)==len(train_data)) & (len(test_data_custom)==len(test_data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_random_images(dataset:torch.utils.data.dataset.Dataset,\n                          classes:List[str]=None,\n                          n:int=10,\n                          display_shape:bool=True,\n                          seed:int=None):\n    if n>10:\n        n=10\n        display_shape=False\n        print(\"n shouldn't be larger than 10\")\n    \n    if seed:\n        random.seed(seed)\n    \n    random_samples_idx=random.sample(range(len(dataset)),k=n)\n    \n    for i, targ_sample in enumerate(random_samples_idx):\n        targ_image, targ_label=dataset[targ_sample][0], dataset[targ_sample][1]\n        \n        targ_image_adjust=targ_image.permute(1,2,0)\n        \n        plt.subplot(1,n,i+1)\n        plt.imshow(targ_image_adjust)\n        plt.axis(\"off\")\n        if classes:\n            title=f\"class: {classes[targ_label]}\"\n            if display_shape:\n                title=title+f\"\\nshape{targ_image_adjust.shape}\"\n        plt.title(title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_random_images(train_data,\n                      n=5,\n                      classes=class_names,\n                      seed=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_random_images(train_data,\n                      n=11,\n                      classes=class_names,\n                      seed=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader_custom=DataLoader(dataset=train_data_custom,\n                                   batch_size=1,\n                                   num_workers=0,\n                                   shuffle=True)\ntest_dataloader_custom=DataLoader(dataset=test_data_custom,\n                                  batch_size=1,\n                                  num_workers=0,\n                                  shuffle=False)\n\ntrain_dataloader,test_dataloader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = next(iter(train_dataloader_custom))\n\nprint(f\"{img.shape}->[batch,cc,h,w]\")\nprint(f\"{label.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tain_transforms=transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n    transforms.ToTensor()\n])\ntest_transforms=transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path_list=list(image_path.glob(\"*/*/*.jpg\"))\n\nplot_transformed_images(\n    image_paths=image_path_list,\n    transform=train_transforms,\n    n=3,\n    seed=None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_transform=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.ToTensor(),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\ntrain_data_simple=datasets.ImageFolder(root=train_dir,\n                                       transform=simple_transform,\n                                       )\ntest_data_simple=datasets.ImageFolder(root=test_dir,\n                                      transform=simple_transform)\n\nimport os \nfrom torch.utils.data import DataLoader\nBATCH_SIZE=32\nNUM_WORKERS=os.cpu_count()\nprint(BATCH_SIZE,NUM_WORKERS)\n\ntrain_dataloader_simple=DataLoader(train_data_simple,\n                                   batch_size=BATCH_SIZE,\n                                   shuffle=True,\n                                   num_workers=NUM_WORKERS)\ntest_dataloader_simple=DataLoader(test_data_simple,\n                                 batch_size=BATCH_SIZE,\n                                 shuffle=False,\n                                 num_workers=NUM_WORKERS)\n\ntrain_dataloader_simple,test_dataloader_simple","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TinyVGG(nn.Module):\n    def __init__(self,input_shape:int,hidden_units:int, output_shape):\n        super().__init__()\n        self.conv_block1=nn.Sequential(\n            nn.Conv2d(in_channels=input_shape,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,\n                         stride=2)\n        )\n        self.conv_block2=nn.Sequential(\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.classifier=nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=hidden_units*15*15,out_features=output_shape)\n        )\n    def forward(self,x:torch.Tensor):\n            x=self.conv_block1(x)\n            x=self.conv_block2(x)\n            print(x.shape)\n            x=self.classifier(x)\n            return x\n        \ntorch.manual_seed(29)\nmodel_0=TinyVGG(3,10,len(train_data.classes)).to(device)\nmodel_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_batch, label_batch=next(iter(train_dataloader_simple))\n\nimg_single, label_single=img_batch[0].unsqueeze(dim=0), label_batch[0]\nprint(img_single.shape)\n\nmodel_0.eval()\nwith torch.inference_mode():\n    pred=model_0(img_single.to(device))\n\nprint(\"\\n\")\nprint(pred)\nprint(torch.softmax(pred,dim=1))\nprint(torch.argmax(torch.softmax(pred,dim=1),dim=1))\nprint(label_single)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import torchinfo\nexcept:\n    !pip install torchinfo\n    import torchinfo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\nsummary(model_0,input_size=[1,3,64,64])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model:torch.nn.Module,\n               dataloader:torch.utils.data.DataLoader,\n               loss_fn:torch.nn.Module,\n               optimizer:torch.optim.Optimizer):\n    model.train()\n    \n    train_loss, train_acc=0,0\n    \n    for batch, (X,y) in enumerate(dataloader):\n        X,y=X.to(device), y.to(device)\n        \n        y_pred=model(X)\n        \n        loss=loss_fn(y_pred,y)\n        train_loss+=loss.item()\n        \n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n        train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n    \n    # adjust metrics to get average loss and accuracy pre batch\n    train_loss=train_loss / len(dataloader)\n    train_acc=train_acc/ len(dataloader)\n    \n    return train_loss, train_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_step(model:torch.nn.Module,\n              dataloader:torch.utils.data.DataLoader,\n              loss_fn:torch.nn.Module):\n    \n    model.eval()\n    \n    test_loss, test_acc=0,0\n    \n    with torch.inference_mode():\n        for batch, (X,y) in enumerate(dataloader):\n            X,y=X.to(device), y.to(device)\n            \n            test_pred_logits=model(X)\n            \n            loss=loss_fn(test_pred_logits,y)\n            test_loss+=loss.item()\n            \n            test_pred_labels=test_pred_logits.argmax(dim=1)\n            test_acc+=((test_pred_labels==y).sum().item() / len(test_pred_labels))\n            \n    test_loss/=len(dataloader)\n    test_acc/=len(dataloader)\n    return test_loss, test_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train(model:torch.nn.Module,\n          train_dataloader:torch.utils.data.DataLoader,\n          test_dataloader:torch.utils.data.DataLoader,\n          optimizer:torch.optim.Optimizer,\n          loss_fn:torch.nn.Module,\n          epochs:int=5):\n    results={\"train_loss\":[],\n             \"train_acc\":[],\n             \"test_loss\":[],\n             \"test_acc\":[]}\n    \n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc=train_step(model=model,\n                                         dataloader=train_dataloader,\n                                         loss_fn=loss_fn,\n                                         optimizer=optimizer)\n        test_loss, test_acc=test_step(model=model,\n                                      dataloader=test_dataloader,\n                                      loss_fn=loss_fn)\n        \n        print(\n            f\"epoch+1 | \" \n            f\"train_loss: {train_loss} | \"\n            f\"train_acc: {train_acc} | \"            \n            f\"test_loss: {test_loss} | \"\n            f\"test_acc: {test_acc} \"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n    return results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(29)\ntorch.cuda.manual_seed(29)\n\nNUM_EPOCHS=5\nmodel_0=TinyVGG(input_shape=3,\n                hidden_units=10,\n                output_shape=len(train_data.classes)).to(device)\n\nloss_fn=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(params=model_0.parameters(),lr=0.01)\n\nfrom timeit import default_timer as timer\nstart_time=timer()\n\nmodel_0_res=train(model=model_0,\n                  train_dataloader=train_dataloader_simple,\n                  test_dataloader=test_dataloader_simple,\n                  optimizer=optimizer,\n                  loss_fn=loss_fn,\n                  epochs=NUM_EPOCHS)\n\nend_time=timer()\nprint(end_time - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(results:Dict[str,List[float]]):\n    loss=results[\"train_loss\"]\n    test_loss=results[\"test_loss\"]\n    \n    accuracy=results[\"train_acc\"]\n    test_accuracy=results[\"test_acc\"]\n    \n    epochs=range(len(results[\"train_loss\"]))\n    \n    plt.figure(figsize=(15,7))\n    \n    plt.subplot(1,2,1)\n    plt.plot(epochs,loss,label=\"train_loss\")\n    plt.plot(epochs,test_loss,label=\"test_loss\")\n    plt.legend()\n    \n    plt.subplot(1,2,2)\n    plt.plot(epochs,accuracy,label=\"train_acc\")\n    plt.plot(epochs,test_accuracy,label=\"test_acc\")\n    plt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(model_0_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform_trivial_augment=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n    transforms.ToTensor()\n])\n\ntest_transform=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_augmented=datasets.ImageFolder(train_dir,transform=train_transform_trivial_augment)\ntest_data_simple=datasets.ImageFolder(test_dir,transform=test_transform)\n\ntrain_data_augmented,test_data_simple","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nBATCH_SIZE=32\nNUM_WORKERS=os.cpu_count()\n\ntorch.manual_seed(29)\n\ntrain_dataloader_augmented=DataLoader(train_data_augmented,\n                                      batch_size=BATCH_SIZE,\n                                      shuffle=True,\n                                      num_workers=NUM_WORKERS)\n\ntest_dataloader_simple=DataLoader(test_data_simple,\n                                  batch_size=BATCH_SIZE,\n                                  shuffle=False,\n                                  num_workers=NUM_WORKERS)\n\ntrain_dataloader_augmented, test_dataloader_simple","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nmodel_1=TinyVGG(\n    input_shape=3,\n    hidden_units=10,\n    output_shape=len(train_data_augmented.classes)\n).to(device)\nmodel_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(29)\ntorch.cuda.manual_seed(29)\n\nNUM_EPOCHS=5\n\nloss_fn=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model_1.parameters(),0.01)\n\nfrom timeit import default_timer as timer\nstart_time=timer()\n\nmodel_1_res=train(model_1,\n                  train_dataloader_augmented,\n                  test_dataloader_simple,\n                  optimizer,\n                  loss_fn,\n                  NUM_EPOCHS)\n\nend_time=timer()\nprint(end_time-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(model_1_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0_df=pd.DataFrame(model_0_res)\nmodel_1_df=pd.DataFrame(model_1_res)\nmodel_0_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=range(len(model_0_df))\n\nplt.subplot(2,2,1)\nplt.plot(epochs,model_0_df[\"train_loss\"],label=\"model_0\")\nplt.legend()\n\nplt.subplot(2,2,2)\nplt.plot(epochs,model_1_df[\"train_loss\"],label=\"model_1\")\nplt.legend()\n\nplt.subplot(2,2,3)\nplt.plot(epochs,model_0_df[\"train_acc\"],label=\"model_0\")\nplt.plot(epochs,model_1_df[\"train_acc\"],label=\"model_1\")\nplt.legend()\n\nplt.subplot(2,2,4)\nplt.plot(epochs,model_0_df[\"test_acc\"],label=\"model_0\")\nplt.plot(epochs,model_1_df[\"test_acc\"],label=\"model_1\")\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\ncustom_image_path=data_path / \"04-pizza-dad.jpeg\"\n\nif not custom_image_path.is_file():\n    with open(custom_image_path,\"wb\") as f:\n        request=requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n        f.write(request.content)\n        \n    \nelse:\n    print(\"exists\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\n\ncustom_image_uint8=torchvision.io.read_image(str(custom_image_path))\n\nprint(custom_image_uint8)\nprint(custom_image_uint8.shape)\nprint(custom_image_uint8.dtype)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try to make prediction on image inuint8 format (this will error)\nmodel_1.eval()\nwith torch.inference_mode():\n    model_1(custom_image_uint8.to(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_image=torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n\ncustom_image=custom_image / 255.\n\nprint(custom_image)\nprint(custom_image.shape)\nprint(custom_image.dtype)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(custom_image.permute(1,2,0)) # CHW to HWC  fro matplotlib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_image_transform=transforms.Compose([\n    transforms.Resize((64,64))\n])\n\ncustom_image_transformed=custom_image_transform(custom_image)\n\ncustom_image.shape, custom_image_transformed.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.eval()\nwith torch.inference_mode():\n    custom_image_pred=model_1(custom_image_transformed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.eval()\nwith torch.inference_mode():\n    custom_image_pred=model_1(custom_image_transformed.to(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.eval()\nwith torch.inference_mode():\n    \n    # add an extra dimension  to imagae   -> BCHW batch size\n    custom_image_transformed_with_batch_size=custom_image_transformed.unsqueeze(dim=0)\n    \n    print(custom_image_transformed.shape)\n    print(custom_image_transformed_with_batch_size.shape)\n    \n    custom_image_pred=model_1(custom_image_transformed_with_batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_image_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(custom_image_pred)\n\ncustom_image_pred_probs=torch.softmax(custom_image_pred,dim=1)\nprint(custom_image_pred_probs)\n\ncustom_image_pred_label=torch.argmax(custom_image_pred_probs,dim=1)\nprint(custom_image_pred_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_image_pred_class=class_names[custom_image_pred_label.cpu()] # putt this on cpu otherwise error\ncustom_image_pred_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_and_plot_image(model:torch.nn.Module,\n                        image_path:str,\n                        class_names:List[str]=None,\n                        transform=None,\n                        device:torch.device=device):\n    target_image=torchvision.io.read_image(str(image_path)).type(torch.float32)\n    \n    target_image=target_image / 255.\n    \n    if transform:\n        target_image=transform(target_image)\n        \n    model.to(device)\n    \n    model.eval()\n    with torch.inference_mode():\n        target_image=target_image.unsqueeze(dim=0)\n        \n        target_image_pred=model(target_image)\n    \n    target_image_pred_probs=torch.softmax(target_image_pred,dim=1)    \n        \n    target_image_pred_label=torch.argmax(target_image_pred_probs,dim=1)\n    \n    plt.imshow(target_image.squeeze().permute(1,2,0))\n    \n    if class_names:\n        title=f\"{class_names[target_image_pred_label.cpu()]} | {target_image_pred_probs.max().cpu()}\"\n    else:\n        title=f\"{class_names[target_image_pred_label.cpu()]} | {target_image_pred_probs.max().cpu()}\"\n        \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_and_plot_image(model_1,\n                    custom_image_path,\n                    class_names,\n                    custom_image_transform,\n                    device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercise","metadata":{}},{"cell_type":"markdown","source":"## 1] Our models are underperforming (not fitting the data well). What are 3 methods for preventing underfitting? Write them down and explain each with a sentence.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:04.945703Z","iopub.execute_input":"2024-02-16T10:09:04.946189Z","iopub.status.idle":"2024-02-16T10:09:04.952181Z","shell.execute_reply.started":"2024-02-16T10:09:04.946153Z","shell.execute_reply":"2024-02-16T10:09:04.950612Z"}}},{"cell_type":"markdown","source":"### 1} Add more features \n#### -> Adding more relevant features to the model can help it better capture the underlying relationships in the data.\n\n### 2} Increase model complexity \n#### -> Using a more complex model architecture with more parameters can allow the model to fit a wider range of functions.\n\n### 3} Reduce regularization \n#### -> Decreasing regularization techniques like L1/L2 regularization reduces restrictions on the model and allows it to fit the training data better.","metadata":{}},{"cell_type":"markdown","source":"## 2] Recreate the data loading functions we built in sections 1, 2, 3 and 4. You should have train and test DataLoader's ready to use.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:04.954717Z","iopub.execute_input":"2024-02-16T10:09:04.955372Z","iopub.status.idle":"2024-02-16T10:09:04.965295Z","shell.execute_reply.started":"2024-02-16T10:09:04.955328Z","shell.execute_reply":"2024-02-16T10:09:04.963939Z"}}},{"cell_type":"code","source":"import requests\nimport zipfile\nfrom pathlib import Path\n\ndata_path=Path(\"data/\")\nimage_path=data_path / \"pizza_staek_sushi\"\n\nimage_path.mkdir(parents=True,exist_ok=True)\n\nwith open(data_path / \"pizza_staek_sushi.zip\",\"wb\") as f:\n    request=requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n    f.write(request.content)\n    \nwith zipfile.ZipFile(data_path / \"pizza_staek_sushi.zip\",\"r\") as f:\n    f.extractall(image_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.249667Z","iopub.execute_input":"2024-02-16T11:55:40.250206Z","iopub.status.idle":"2024-02-16T11:55:40.767640Z","shell.execute_reply.started":"2024-02-16T11:55:40.250167Z","shell.execute_reply":"2024-02-16T11:55:40.766238Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dir=image_path / \"train\"\ntest_dir=image_path / \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.770361Z","iopub.execute_input":"2024-02-16T11:55:40.770862Z","iopub.status.idle":"2024-02-16T11:55:40.777320Z","shell.execute_reply.started":"2024-02-16T11:55:40.770820Z","shell.execute_reply":"2024-02-16T11:55:40.775605Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.778962Z","iopub.execute_input":"2024-02-16T11:55:40.779358Z","iopub.status.idle":"2024-02-16T11:55:40.787669Z","shell.execute_reply.started":"2024-02-16T11:55:40.779328Z","shell.execute_reply":"2024-02-16T11:55:40.786679Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_transform=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.RandomHorizontalFlip(p=0.6),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.789219Z","iopub.execute_input":"2024-02-16T11:55:40.789723Z","iopub.status.idle":"2024-02-16T11:55:40.800604Z","shell.execute_reply.started":"2024-02-16T11:55:40.789679Z","shell.execute_reply":"2024-02-16T11:55:40.799135Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_data=datasets.ImageFolder(root=train_dir,\n                                transform=data_transform,\n                                target_transform=None)\ntest_data=datasets.ImageFolder(root=test_dir,\n                                transform=data_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.804325Z","iopub.execute_input":"2024-02-16T11:55:40.804751Z","iopub.status.idle":"2024-02-16T11:55:40.815282Z","shell.execute_reply.started":"2024-02-16T11:55:40.804721Z","shell.execute_reply":"2024-02-16T11:55:40.814083Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class_names=train_data.classes","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.818081Z","iopub.execute_input":"2024-02-16T11:55:40.819674Z","iopub.status.idle":"2024-02-16T11:55:40.829316Z","shell.execute_reply.started":"2024-02-16T11:55:40.819620Z","shell.execute_reply":"2024-02-16T11:55:40.827536Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class_dict=train_data.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.830792Z","iopub.execute_input":"2024-02-16T11:55:40.831424Z","iopub.status.idle":"2024-02-16T11:55:40.840559Z","shell.execute_reply.started":"2024-02-16T11:55:40.831386Z","shell.execute_reply":"2024-02-16T11:55:40.839544Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=1\nNUM_WORKERS=1\n\ntrain_dataloader=DataLoader(dataset=train_data,\n                            batch_size=BATCH_SIZE,\n                            num_workers=NUM_WORKERS,\n                            shuffle=True)\ntest_dataloader=DataLoader(dataset=test_data,\n                            batch_size=BATCH_SIZE,\n                            num_workers=NUM_WORKERS,\n                           shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.841847Z","iopub.execute_input":"2024-02-16T11:55:40.842451Z","iopub.status.idle":"2024-02-16T11:55:40.853623Z","shell.execute_reply.started":"2024-02-16T11:55:40.842416Z","shell.execute_reply":"2024-02-16T11:55:40.852629Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## 3] Recreate model_0 we built in section 7.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:04.967305Z","iopub.execute_input":"2024-02-16T10:09:04.968027Z","iopub.status.idle":"2024-02-16T10:09:04.975944Z","shell.execute_reply.started":"2024-02-16T10:09:04.967982Z","shell.execute_reply":"2024-02-16T10:09:04.974864Z"}}},{"cell_type":"code","source":"transform=transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.854881Z","iopub.execute_input":"2024-02-16T11:55:40.855589Z","iopub.status.idle":"2024-02-16T11:55:40.867799Z","shell.execute_reply.started":"2024-02-16T11:55:40.855555Z","shell.execute_reply":"2024-02-16T11:55:40.866306Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_data_1=datasets.ImageFolder(root=train_dir,\n                                  transform=transform\n                                  )\ntest_data_1=datasets.ImageFolder(root=test_dir,\n                                  transform=transform\n                                  )\n\nimport os\n\nBATCH_SIZE=32\nNUM_WORKERS=os.cpu_count()\n\ntrain_dataloader_1=DataLoader(train_data_1,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS,\n                              shuffle=True)\ntest_dataloader_1=DataLoader(train_data_1,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS,\n                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.869540Z","iopub.execute_input":"2024-02-16T11:55:40.871148Z","iopub.status.idle":"2024-02-16T11:55:40.883677Z","shell.execute_reply.started":"2024-02-16T11:55:40.871098Z","shell.execute_reply":"2024-02-16T11:55:40.882529Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from torch import nn","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.885171Z","iopub.execute_input":"2024-02-16T11:55:40.885632Z","iopub.status.idle":"2024-02-16T11:55:40.894027Z","shell.execute_reply.started":"2024-02-16T11:55:40.885598Z","shell.execute_reply":"2024-02-16T11:55:40.892935Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.895892Z","iopub.execute_input":"2024-02-16T11:55:40.896430Z","iopub.status.idle":"2024-02-16T11:55:40.907697Z","shell.execute_reply.started":"2024-02-16T11:55:40.896385Z","shell.execute_reply":"2024-02-16T11:55:40.906593Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelRebuild(nn.Module):\n    def __init__(self,input_shape:int,hidden_units:int, output_shape):\n        super().__init__()\n        self.conv_block1=nn.Sequential(\n            nn.Conv2d(in_channels=input_shape,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,\n                         stride=2)\n        )\n        self.conv_block2=nn.Sequential(\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.classifier=nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=hidden_units*15*15,out_features=output_shape)\n        )\n    def forward(self,x:torch.Tensor):\n            x=self.conv_block1(x)\n            x=self.conv_block2(x)\n            print(x.shape)\n            x=self.classifier(x)\n            return x\n        \ntorch.manual_seed(29)\nmodel_e=ModelRebuild(3,10,len(train_data_1.classes)).to(device)\nmodel_e","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.909556Z","iopub.execute_input":"2024-02-16T11:55:40.910378Z","iopub.status.idle":"2024-02-16T11:55:40.934724Z","shell.execute_reply.started":"2024-02-16T11:55:40.910332Z","shell.execute_reply":"2024-02-16T11:55:40.933139Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"ModelRebuild(\n  (conv_block1): Sequential(\n    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_block2): Sequential(\n    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=2250, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4] Create training and testing functions for model_0.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:04.978159Z","iopub.execute_input":"2024-02-16T10:09:04.979584Z","iopub.status.idle":"2024-02-16T10:09:04.989649Z","shell.execute_reply.started":"2024-02-16T10:09:04.979534Z","shell.execute_reply":"2024-02-16T10:09:04.987877Z"}}},{"cell_type":"code","source":"def train_step(model:torch.nn.Module,\n               dataloader:torch.utils.data.DataLoader,\n               loss_fn:torch.nn.Module,\n               optimizer:torch.optim.Optimizer):\n    model.train()\n    \n    train_loss, train_acc=0,0\n    \n    for batch, (X,y) in enumerate(dataloader):\n        X,y=X.to(device), y.to(device)\n        \n        y_pred=model(X)\n        \n        loss=loss_fn(y_pred,y)\n        train_loss+=loss.item()\n        \n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n        train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n    \n    # adjust metrics to get average loss and accuracy pre batch\n    train_loss=train_loss / len(dataloader)\n    train_acc=train_acc/ len(dataloader)\n    \n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.940558Z","iopub.execute_input":"2024-02-16T11:55:40.941278Z","iopub.status.idle":"2024-02-16T11:55:40.950851Z","shell.execute_reply.started":"2024-02-16T11:55:40.941240Z","shell.execute_reply":"2024-02-16T11:55:40.949581Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def test_step(model:torch.nn.Module,\n              dataloader:torch.utils.data.DataLoader,\n              loss_fn:torch.nn.Module):\n    \n    model.eval()\n    \n    test_loss, test_acc=0,0\n    \n    with torch.inference_mode():\n        for batch, (X,y) in enumerate(dataloader):\n            X,y=X.to(device), y.to(device)\n            \n            test_pred_logits=model(X)\n            \n            loss=loss_fn(test_pred_logits,y)\n            test_loss+=loss.item()\n            \n            test_pred_labels=test_pred_logits.argmax(dim=1)\n            test_acc+=((test_pred_labels==y).sum().item() / len(test_pred_labels))\n            \n    test_loss/=len(dataloader)\n    test_acc/=len(dataloader)\n    return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.952716Z","iopub.execute_input":"2024-02-16T11:55:40.954075Z","iopub.status.idle":"2024-02-16T11:55:40.969153Z","shell.execute_reply.started":"2024-02-16T11:55:40.954014Z","shell.execute_reply":"2024-02-16T11:55:40.967533Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train(model:torch.nn.Module,\n          train_dataloader:torch.utils.data.DataLoader,\n          test_dataloader:torch.utils.data.DataLoader,\n          optimizer:torch.optim.Optimizer,\n          loss_fn:torch.nn.Module,\n          epochs:int=5):\n    results={\"train_loss\":[],\n             \"train_acc\":[],\n             \"test_loss\":[],\n             \"test_acc\":[]}\n    \n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc=train_step(model=model,\n                                         dataloader=train_dataloader,\n                                         loss_fn=loss_fn,\n                                         optimizer=optimizer)\n        test_loss, test_acc=test_step(model=model,\n                                      dataloader=test_dataloader,\n                                      loss_fn=loss_fn)\n        \n        print(\n            f\"epoch+1 | \" \n            f\"train_loss: {train_loss} | \"\n            f\"train_acc: {train_acc} | \"            \n            f\"test_loss: {test_loss} | \"\n            f\"test_acc: {test_acc} \"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.970761Z","iopub.execute_input":"2024-02-16T11:55:40.971195Z","iopub.status.idle":"2024-02-16T11:55:40.982735Z","shell.execute_reply.started":"2024-02-16T11:55:40.971161Z","shell.execute_reply":"2024-02-16T11:55:40.981773Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## 5] Try training the model you made in exercise 3 for 5, 20 and 50 epochs, what happens to the results?\n- Use torch.optim.Adam() with a learning rate of 0.001 as the optimizer.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:10.224779Z","iopub.execute_input":"2024-02-16T10:09:10.225240Z","iopub.status.idle":"2024-02-16T10:09:10.243943Z","shell.execute_reply.started":"2024-02-16T10:09:10.225210Z","shell.execute_reply":"2024-02-16T10:09:10.241554Z"}}},{"cell_type":"code","source":"torch.manual_seed(29)\ntorch.cuda.manual_seed(29)\n\nNUM_EPOCHS=5\n\nloss_fn=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model_e.parameters(),0.001)\n\nfrom timeit import default_timer as timer\nstart_time=timer()\n\nmodel_e_res=train(model_e,\n                  train_dataloader_1,\n                  test_dataloader_1,\n                  optimizer,\n                  loss_fn,\n                  NUM_EPOCHS)\n\nend_time=timer()\nprint(end_time-start_time)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:40.984367Z","iopub.execute_input":"2024-02-16T11:55:40.984930Z","iopub.status.idle":"2024-02-16T11:55:49.960901Z","shell.execute_reply.started":"2024-02-16T11:55:40.984899Z","shell.execute_reply":"2024-02-16T11:55:49.958984Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f7f80d59414e44b9dd8efc4c4cab33"}},"metadata":{}},{"name":"stdout","text":"torch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\nepoch+1 | train_loss: 1.102908879518509 | train_acc: 0.265625 | test_loss: 1.0963498651981354 | test_acc: 0.43359375 \ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\nepoch+1 | train_loss: 1.1034195125102997 | train_acc: 0.28515625 | test_loss: 1.0867156684398651 | test_acc: 0.40234375 \ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\nepoch+1 | train_loss: 1.1009541451931 | train_acc: 0.3203125 | test_loss: 1.076808586716652 | test_acc: 0.48828125 \ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\nepoch+1 | train_loss: 1.08011132478714 | train_acc: 0.4609375 | test_loss: 1.0490489453077316 | test_acc: 0.5078125 \ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([32, 10, 15, 15])\ntorch.Size([1, 10, 15, 15])\nepoch+1 | train_loss: 0.9985810816287994 | train_acc: 0.6328125 | test_loss: 0.9468627944588661 | test_acc: 0.64453125 \n8.954170368999257\n","output_type":"stream"}]},{"cell_type":"code","source":"model_e_res[\"test_acc\"][-1]","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:49.963263Z","iopub.execute_input":"2024-02-16T11:55:49.963733Z","iopub.status.idle":"2024-02-16T11:55:49.974098Z","shell.execute_reply.started":"2024-02-16T11:55:49.963695Z","shell.execute_reply":"2024-02-16T11:55:49.972839Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"0.64453125"},"metadata":{}}]},{"cell_type":"markdown","source":"## 6] Double the number of hidden units in your model and train it for 20 epochs, what happens to the results?\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:17.945011Z","iopub.execute_input":"2024-02-16T10:09:17.945463Z","iopub.status.idle":"2024-02-16T10:09:17.951097Z","shell.execute_reply.started":"2024-02-16T10:09:17.945431Z","shell.execute_reply":"2024-02-16T10:09:17.949915Z"}}},{"cell_type":"code","source":"torch.manual_seed(29)\ntorch.cuda.manual_seed(29)\n\nNUM_EPOCHS=20\n\nloss_fn=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model_e.parameters(),0.001)\n\nfrom timeit import default_timer as timer\nstart_time=timer()\n\nmodel_e_double_units=ModelRebuild(3,20,len(train_data_1.classes)).to(device)\nmodel_e_double_units_res=train(model_e_double_units,\n                  train_dataloader_1,\n                  test_dataloader_1,\n                  optimizer,\n                  loss_fn,\n                  NUM_EPOCHS)\n\nend_time=timer()\nprint(end_time-start_time)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:55:49.975722Z","iopub.execute_input":"2024-02-16T11:55:49.976139Z","iopub.status.idle":"2024-02-16T11:56:38.662533Z","shell.execute_reply.started":"2024-02-16T11:55:49.976107Z","shell.execute_reply":"2024-02-16T11:56:38.660651Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76f969d78b334596b15faa093124a622"}},"metadata":{}},{"name":"stdout","text":"torch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0952823460102081 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0955328047275543 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0957183539867401 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.096092700958252 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0961428433656693 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0958353132009506 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.095887765288353 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1030257493257523 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.102910578250885 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1029106080532074 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1029707789421082 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0954486727714539 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1030968576669693 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0955877602100372 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0961253494024277 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1027024686336517 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.096404418349266 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0956271141767502 | train_acc: 0.3984375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.1029525399208069 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([32, 20, 15, 15])\ntorch.Size([1, 20, 15, 15])\nepoch+1 | train_loss: 1.0957854688167572 | train_acc: 0.27734375 | test_loss: 1.095036894083023 | test_acc: 0.3984375 \n48.66922840299958\n","output_type":"stream"}]},{"cell_type":"code","source":"model_e_double_units_res[\"test_acc\"][-1]","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:56:38.665761Z","iopub.execute_input":"2024-02-16T11:56:38.666371Z","iopub.status.idle":"2024-02-16T11:56:38.677375Z","shell.execute_reply.started":"2024-02-16T11:56:38.666313Z","shell.execute_reply":"2024-02-16T11:56:38.676122Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0.3984375"},"metadata":{}}]},{"cell_type":"markdown","source":"## 7] Double the data you're using with your model and train it for 20 epochs, what happens to the results?\n- Note: You can use the custom data creation notebook to scale up your Food101 dataset.\n- You can also find the already formatted double data (20% instead of 10% subset) dataset on GitHub, you will need to write download code like in exercise 2 to get it into this notebook.\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T10:09:23.947572Z","iopub.execute_input":"2024-02-16T10:09:23.948082Z","iopub.status.idle":"2024-02-16T10:09:23.957046Z","shell.execute_reply.started":"2024-02-16T10:09:23.948046Z","shell.execute_reply":"2024-02-16T10:09:23.955435Z"}}},{"cell_type":"code","source":"data_path_1=Path(\"data/\")\nimage_path_1=data_path_1 / \"pizza_steak_sushi_20_percent\"\n\nimage_path_1.mkdir(parents=True,exist_ok=True)\n\n# print(requests.head(\"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip\"))\n\nwith open(data_path_1 / \"pizza_steak_sushi_20_percent.zip\",\"wb\") as f:\n    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n    f.write(request.content)\n    \nwith zipfile.ZipFile(data_path_1 / \"pizza_steak_sushi_20_percent.zip\",\"r\") as f:\n    f.extractall(image_path_1)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:13:01.408647Z","iopub.execute_input":"2024-02-16T12:13:01.409185Z","iopub.status.idle":"2024-02-16T12:13:02.725648Z","shell.execute_reply.started":"2024-02-16T12:13:01.409151Z","shell.execute_reply":"2024-02-16T12:13:02.723862Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_dir_1=image_path_1 / \"train\"\ntest_dir_1=image_path_1 / \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:15:56.948247Z","iopub.execute_input":"2024-02-16T12:15:56.948786Z","iopub.status.idle":"2024-02-16T12:15:56.954896Z","shell.execute_reply.started":"2024-02-16T12:15:56.948750Z","shell.execute_reply":"2024-02-16T12:15:56.953336Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_data_1=datasets.ImageFolder(root=train_dir_1,\n                                transform=data_transform,\n                                target_transform=None)\ntest_data_1=datasets.ImageFolder(root=test_dir_1,\n                                transform=data_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:15:59.302803Z","iopub.execute_input":"2024-02-16T12:15:59.303268Z","iopub.status.idle":"2024-02-16T12:15:59.315978Z","shell.execute_reply.started":"2024-02-16T12:15:59.303234Z","shell.execute_reply":"2024-02-16T12:15:59.314686Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class_names_1=train_data_1.classes","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:16:52.221931Z","iopub.execute_input":"2024-02-16T12:16:52.222697Z","iopub.status.idle":"2024-02-16T12:16:52.228027Z","shell.execute_reply.started":"2024-02-16T12:16:52.222641Z","shell.execute_reply":"2024-02-16T12:16:52.227136Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class_dict_1=train_data_1.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:17:12.812452Z","iopub.execute_input":"2024-02-16T12:17:12.813212Z","iopub.status.idle":"2024-02-16T12:17:12.818827Z","shell.execute_reply.started":"2024-02-16T12:17:12.813164Z","shell.execute_reply":"2024-02-16T12:17:12.817730Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_data_1=datasets.ImageFolder(root=train_dir,\n                                  transform=transform\n                                  )\ntest_data_1=datasets.ImageFolder(root=test_dir,\n                                  transform=transform\n                                  )\n\nimport os\n\nBATCH_SIZE=32\nNUM_WORKERS=os.cpu_count()\n\ntrain_dataloader_1=DataLoader(train_data_1,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS,\n                              shuffle=True)\ntest_dataloader_1=DataLoader(train_data_1,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS,\n                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:19:19.871873Z","iopub.execute_input":"2024-02-16T12:19:19.872334Z","iopub.status.idle":"2024-02-16T12:19:19.884629Z","shell.execute_reply.started":"2024-02-16T12:19:19.872297Z","shell.execute_reply":"2024-02-16T12:19:19.883171Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model_e_double_data=ModelRebuild(3,10,len(train_data_1.classes)).to(device)\nmodel_e_double_data","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:20:12.737647Z","iopub.execute_input":"2024-02-16T12:20:12.738184Z","iopub.status.idle":"2024-02-16T12:20:12.750295Z","shell.execute_reply.started":"2024-02-16T12:20:12.738147Z","shell.execute_reply":"2024-02-16T12:20:12.749316Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"ModelRebuild(\n  (conv_block1): Sequential(\n    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv_block2): Sequential(\n    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=2250, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8] Make a prediction on your own custom image of pizza/steak/sushi (you could even download one from the internet) and share your prediction.\n- Does the model you trained in exercise 7 get it right?\n- If not, what do you think you could do to improve it?","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}